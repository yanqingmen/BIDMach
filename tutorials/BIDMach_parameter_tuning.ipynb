{
 "metadata": {
  "name": "",
  "signature": "sha256:fb9af722173f4049ec9e7f087dd966a875aa29e99d44f3120058a28ede68140d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "BIDMach: parameter tuning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we'll explore automated parameter exploration by grid search. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import BIDMat.{CMat,CSMat,DMat,Dict,IDict,FMat,FND,GDMat,GMat,GIMat,GSDMat,GSMat,HMat,Image,IMat,Mat,SMat,SBMat,SDMat}\n",
      "import BIDMat.MatFunctions._\n",
      "import BIDMat.SciFunctions._\n",
      "import BIDMat.Solvers._\n",
      "import BIDMat.Plotting._\n",
      "import BIDMach.Learner\n",
      "import BIDMach.models.{FM,GLM,KMeans,KMeansw,ICA,LDA,LDAgibbs,NMF,RandomForest,SFA}\n",
      "import BIDMach.datasources.{MatDS,FilesDS,SFilesDS}\n",
      "import BIDMach.mixins.{CosineSim,Perplexity,Top,L1Regularizer,L2Regularizer}\n",
      "import BIDMach.updaters.{ADAGrad,Batch,BatchNorm,IncMult,IncNorm,Telescoping}\n",
      "import BIDMach.causal.{IPTW}\n",
      "\n",
      "Mat.checkMKL\n",
      "Mat.checkCUDA\n",
      "if (Mat.hasCUDA > 0) GPUmem"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 CUDA device found, CUDA version 6.5\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "(0.8837719,3795771392,4294967296)"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Dataset: Reuters RCV1 V2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataset is the widely used Reuters news article dataset RCV1 V2. This dataset and several others are loaded by running the script <code>getdata.sh</code> from the BIDMach/scripts directory. The data include both train and test subsets, and train and test labels (cats). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "var dir = \"../data/rcv1/\"             // adjust to point to the BIDMach/data/rcv1 directory\n",
      "tic\n",
      "val train = loadSMat(dir+\"docs.smat.lz4\")\n",
      "val cats = loadFMat(dir+\"cats.fmat.lz4\")\n",
      "val test = loadSMat(dir+\"testdocs.smat.lz4\")\n",
      "val tcats = loadFMat(dir+\"testcats.fmat.lz4\")\n",
      "toc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "1.811"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First lets enumerate some parameter combinations for learning rate and time exponent of the optimizer (texp)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val lrates = col(0.03f, 0.1f, 0.3f, 1f)        // 4 values\n",
      "val texps = col(0.3f, 0.4f, 0.5f, 0.6f, 0.7f)  // 5 values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "  0.30000\n",
        "  0.40000\n",
        "  0.50000\n",
        "  0.60000\n",
        "  0.70000\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The next step is to enumerate all pairs of parameters. We can do this using the kron operator for now, this will eventually be a custom function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val lrateparams = ones(texps.nrows, 1) \u2297 lrates\n",
      "val texpparams = texps \u2297 ones(lrates.nrows,1)\n",
      "lrateparams \\ texpparams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "  0.030000   0.30000\n",
        "   0.10000   0.30000\n",
        "   0.30000   0.30000\n",
        "         1   0.30000\n",
        "  0.030000   0.40000\n",
        "   0.10000   0.40000\n",
        "   0.30000   0.40000\n",
        "         1   0.40000\n",
        "        ..        ..\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's the learner again:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val (mm, opts) = GLM.learner(train, cats, GLM.logistic)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "BIDMach.models.GLM$LearnOptions@12f17837"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To keep things simple, we'll focus on just one category and train many models for it. The \"targmap\" option specifies a mapping from the actual base categories to the model categories. We'll map from category six to all our models:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val nparams = lrateparams.length\n",
      "val targmap = zeros(nparams, 103)\n",
      "targmap(?,6) = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0...\n",
        "  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "opts.targmap = targmap\n",
      "opts.lrate = lrateparams\n",
      "opts.texp = texpparams"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "  0.30000\n",
        "  0.30000\n",
        "  0.30000\n",
        "  0.30000\n",
        "  0.40000\n",
        "  0.40000\n",
        "  0.40000\n",
        "  0.40000\n",
        "       ..\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mm.train"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "corpus perplexity=5582.125391\r\n",
        "pass= 0\r\n",
        " 2.00%, ll=-0.69315, gf=0.855, secs=0.4, GB=0.02, MB/s=59.99, GPUmem=0.84\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16.00%, ll=-0.40513, gf=4.028, secs=0.7, GB=0.13, MB/s=196.88, GPUmem=0.84\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "30.00%, ll=-0.37952, gf=5.155, secs=1.0, GB=0.25, MB/s=242.45, GPUmem=0.84\r\n",
        "44.00%, ll=-0.31513, gf=5.813, secs=1.3, GB=0.36, MB/s=270.14, GPUmem=0.84\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "58.00%, ll=-0.33632, gf=5.274, secs=2.0, GB=0.48, MB/s=243.84, GPUmem=0.84\r\n",
        "72.00%, ll=-0.23368, gf=5.638, secs=2.3, GB=0.59, MB/s=259.20, GPUmem=0.84\r\n",
        "87.00%, ll=-0.29033, gf=5.885, secs=2.6, GB=0.70, MB/s=269.99, GPUmem=0.84\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100.00%, ll=-0.23384, gf=6.076, secs=2.9, GB=0.81, MB/s=276.65, GPUmem=0.84\r\n",
        "pass= 1\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2.00%, ll=-0.28232, gf=6.104, secs=3.0, GB=0.83, MB/s=279.56, GPUmem=0.84\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16.00%, ll=-0.22606, gf=6.230, secs=3.3, GB=0.94, MB/s=284.92, GPUmem=0.84\r\n",
        "30.00%, ll=-0.27916, gf=6.333, secs=3.6, GB=1.05, MB/s=289.11, GPUmem=0.84\r\n",
        "44.00%, ll=-0.28040, gf=6.436, secs=4.0, GB=1.17, MB/s=293.60, GPUmem=0.84\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "58.00%, ll=-0.23271, gf=6.545, secs=4.3, GB=1.28, MB/s=298.47, GPUmem=0.83\r\n",
        "72.00%, ll=-0.19472, gf=6.642, secs=4.6, GB=1.39, MB/s=302.53, GPUmem=0.83\r\n",
        "87.00%, ll=-0.28296, gf=6.716, secs=4.9, GB=1.51, MB/s=305.86, GPUmem=0.83\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100.00%, ll=-0.21991, gf=6.745, secs=5.3, GB=1.61, MB/s=306.17, GPUmem=0.83\r\n",
        "Time=5.2660 secs, gflops=6.75\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val preds = zeros(targmap.nrows, tcats.ncols)       // An array to hold the predictions\n",
      "val (pp, popts) = GLM.predictor(mm.model, test, preds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "BIDMach.models.GLM$LearnOptions@771ad286"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And invoke the predict method on the predictor:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pp.predict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "corpus perplexity=65579.335560\r\n",
        "Predicting\r\n",
        " 3.00%, ll=-4.08879, gf=0.020, secs=0.3, GB=0.00, MB/s= 1.91, GPUmem=0.87\r\n",
        " 6.00%, ll=-1.78565, gf=0.038, secs=0.3, GB=0.00, MB/s= 3.66, GPUmem=0.87\r\n",
        "10.00%, ll=-3.69535, gf=0.055, secs=0.3, GB=0.00, MB/s= 5.19, GPUmem=0.87\r\n",
        "13.00%, ll=-3.79439, gf=0.074, secs=0.3, GB=0.00, MB/s= 7.06, GPUmem=0.87\r\n",
        "16.00%, ll=-2.77067, gf=0.092, secs=0.3, GB=0.00, MB/s= 8.71, GPUmem=0.87\r\n",
        "20.00%, ll=-2.79940, gf=0.109, secs=0.3, GB=0.00, MB/s=10.25, GPUmem=0.87\r\n",
        "23.00%, ll=-3.64225, gf=0.125, secs=0.3, GB=0.00, MB/s=11.75, GPUmem=0.87\r\n",
        "26.00%, ll=-3.11155, gf=0.142, secs=0.3, GB=0.00, MB/s=13.29, GPUmem=0.87\r\n",
        "30.00%, ll=-3.26986, gf=0.159, secs=0.3, GB=0.00, MB/s=14.88, GPUmem=0.87\r\n",
        "33.00%, ll=-2.60778, gf=0.176, secs=0.3, GB=0.01, MB/s=16.53, GPUmem=0.87\r\n",
        "36.00%, ll=-2.68311, gf=0.192, secs=0.3, GB=0.01, MB/s=18.15, GPUmem=0.87\r\n",
        "40.00%, ll=-2.45453, gf=0.208, secs=0.3, GB=0.01, MB/s=19.60, GPUmem=0.87\r\n",
        "43.00%, ll=-2.99318, gf=0.224, secs=0.3, GB=0.01, MB/s=21.09, GPUmem=0.87\r\n",
        "46.00%, ll=-2.64993, gf=0.242, secs=0.3, GB=0.01, MB/s=23.08, GPUmem=0.86\r\n",
        "50.00%, ll=-3.15696, gf=0.257, secs=0.3, GB=0.01, MB/s=24.54, GPUmem=0.86\r\n",
        "53.00%, ll=-2.48460, gf=0.272, secs=0.3, GB=0.01, MB/s=25.92, GPUmem=0.86\r\n",
        "56.00%, ll=-3.76540, gf=0.287, secs=0.3, GB=0.01, MB/s=27.40, GPUmem=0.86\r\n",
        "60.00%, ll=-2.61050, gf=0.301, secs=0.3, GB=0.01, MB/s=28.73, GPUmem=0.86\r\n",
        "63.00%, ll=-2.89073, gf=0.316, secs=0.3, GB=0.01, MB/s=30.03, GPUmem=0.86\r\n",
        "66.00%, ll=-3.84462, gf=0.331, secs=0.3, GB=0.01, MB/s=31.47, GPUmem=0.86\r\n",
        "70.00%, ll=-3.13115, gf=0.345, secs=0.3, GB=0.01, MB/s=32.81, GPUmem=0.86\r\n",
        "73.00%, ll=-2.31032, gf=0.360, secs=0.3, GB=0.01, MB/s=34.23, GPUmem=0.86\r\n",
        "76.00%, ll=-3.60105, gf=0.373, secs=0.3, GB=0.01, MB/s=35.35, GPUmem=0.86\r\n",
        "80.00%, ll=-2.51561, gf=0.388, secs=0.3, GB=0.01, MB/s=36.94, GPUmem=0.86\r\n",
        "83.00%, ll=-2.95237, gf=0.401, secs=0.3, GB=0.01, MB/s=38.22, GPUmem=0.86\r\n",
        "86.00%, ll=-4.13474, gf=0.415, secs=0.3, GB=0.01, MB/s=39.51, GPUmem=0.86\r\n",
        "90.00%, ll=-3.39915, gf=0.428, secs=0.3, GB=0.01, MB/s=40.69, GPUmem=0.86\r\n",
        "93.00%, ll=-1.85190, gf=0.425, secs=0.4, GB=0.01, MB/s=40.51, GPUmem=0.86\r\n",
        "96.00%, ll=-3.48102, gf=0.438, secs=0.4, GB=0.02, MB/s=41.79, GPUmem=0.86\r\n",
        "100.00%, ll=-1.80929, gf=0.450, secs=0.4, GB=0.02, MB/s=42.99, GPUmem=0.86\r\n",
        "Time=0.3710 secs, gflops=0.45\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Although ll values are printed above, they are not meaningful (there is no target to compare the prediction with). \n",
      "\n",
      "We can now compare the accuracy of predictions (preds matrix) with ground truth (the tcats matrix). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val vcats = targmap * tcats                                          // create some virtual cats\n",
      "val lls = mean(ln(1e-7f + vcats \u2218 preds + (1-vcats) \u2218 (1-preds)),2)  // actual logistic likelihood\n",
      "mean(lls)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "-0.23868"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A more thorough measure is ROC area:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val rocs = roc2(preds, vcats, 1-vcats, 100)   // Compute ROC curves for all categories"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "        0        0        0        0        0        0        0        0...\n",
        "  0.84498  0.83089  0.70786  0.68339  0.83812  0.83970  0.76794  0.72687...\n",
        "  0.88921  0.88448  0.82171  0.80113  0.88726  0.88800  0.85490  0.82922...\n",
        "  0.91925  0.91368  0.87920  0.86826  0.91730  0.91980  0.89681  0.88874...\n",
        "  0.93529  0.93241  0.90859  0.90460  0.93325  0.93492  0.92101  0.91841...\n",
        "  0.94632  0.94252  0.93065  0.92722  0.94484  0.94548  0.93427  0.93325...\n",
        "  0.95299  0.95031  0.94252  0.93677  0.95216  0.95281  0.94669  0.94261...\n",
        "  0.95800  0.95698  0.95160  0.94474  0.95744  0.95782  0.95337  0.94854...\n",
        "       ..       ..       ..       ..       ..       ..       ..       ..\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(rocs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "ptolemy.plot.Plot[,0,0,484x239,layout=java.awt.FlowLayout,alignmentX=0.0,alignmentY=0.0,border=,flags=16777225,maximumSize=,minimumSize=,preferredSize=]"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val aucs = mean(rocs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.97690,0.97633,0.97336,0.97058,0.97659,0.97681,0.97469,0.97249,0.97606,0.97700,0.97553,0.97189,0.97517,0.97694,0.97613,0.97292,0.97389,0.97664,0.97639,0.97353"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The maxi2 function will find the max value and its index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "val (bestv, besti) = maxi2(aucs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "9"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And using the best index we can find the optimal parameters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "texpparams(besti) \\ lrateparams(besti)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": []
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.50000,0.10000"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Write the optimal values in the cell below:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<b>Note:</b> although our parameters lay in a square grid, we could have enumerated any sequence of pairs, and we could have searched over more parameters. The learner infrastructure supports more intelligent model optimization (e.g. Bayesian methods). "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}